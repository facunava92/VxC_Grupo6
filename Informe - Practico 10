# Para la distorsión, OpenCV tiene en cuenta los factores radiales y tangenciales. 
# Para el factor radial se usa la siguiente fórmula:
#                Xcorrected = x(1+k1*r^2 + k2*r^4 + k3*r^6)
#                Ycorrected = y(1+k1*r^2 + k2*r^4 + k3*r^6)
# Entonces, para un antiguo punto de píxel en las (x, y)coordenadas de la imagen de entrada, su posición en la imagen de salida
# corregida será (Xcorrected, Ycorrected). 
# La distorsión tangencial se produce porque las lentes que toman imágenes no son perfectamente paralelas al plano de imagen. 
# Se puede corregir a través de las fórmulas:
                Xcorrected = x + [2p1xy + p2(r^2+2x^2)]
                Ycorrected = y + [p1(r^2+2y^2)+ 2p2xy]
# La presencia de la distorsión radial se manifiesta en forma del efecto "barril" u "ojo de pez".

# Calibración de una cámara
# El proceso por el cual se calibra una cámara se puede dividir en tres etapas:
#    • Reunir una cantidad suficiente de información, tanto de imágenes como patrones del tablero de ajedrez.
#    • Refinar las coordenadas de las esquinas del tablero de ajedrez
#    • Optimizar los parámetros de la cámara para eliminar las distorsiones observadas
# Para empezar a reunir información, se hace uso de la función cv2.findChessboardCorners y asi 
# obtener una primera aproximación de las coordenadas de las esquinas del tablero. 
# res, corners = cv2.findChessboardCorners(img, pattern_size)
# El primer argumento recibe la imagen del tablero a analizar y el segundo recibe, indirectamente, 
# la cantidad de esquinas internas que se espera encontrar en la imagen. 
# Este segundo argumento recibe un vector de dos dimensiones, donde la “componente y” corresponde 
# a la cantidad de esquinas internas verticales y la “componente x” a la cantidad de esquinas internas horizontales. 
# La función devuelve en res un valor booleano correspondiente a si encontró o no esquinas. 
# En corners devuelve las coordenadas de las esquinas encontradas.
# Para darle mas precisión a estas coordenadas, se complementa la función anterior con la función cv2.cornerSubPix.
# criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 30, 1e-3)
# corners = cv2.cornerSubPix(img, corners, (10, 10), (-1, -1), criteria)
# El primer argumento recibe la imagen sobre la cual se trabaja. El segundo, 
# las coordenadas aproximadas de las esquinas. El tercero define el tamaño de la zona de búsqueda. 
# El cuarto, indica las zonas a ignorar dentro de las regiones de búsqueda; si se pasa (-1,-1), no se indican zonas.
# El ultimo indica cuando parar la búsqueda. cv2.TERM_CRITERIA_MAX_ITER define el número máximo de iteraciones 
# del algoritmo de búsqueda y cv2.TERM_CRITERIA_EPS determina la diferencia entre dos esquinas consecutivas. 
# Superado cualquiera de estos dos umbrales, la búsqueda se detiene. 
# camera_matrix = np.load('camera_mat.npy')
# dist_coefs = np.load('dist_coefs.npy')    
# h_corners = cv2.undistortPoints(corners, camera_matrix, dist_coefs)
#
# La función cv2.undistortPoints elimina la distorsión en los puntos producida por el lente de la cámara. 
# Como argumento recibe las coordenadas de las esquinas internas y los parámetros intrínsecos de la cámara,
# devuelve coordenadas homogeneas, sin distorsión. 
# Si necesitamos proyectar los puntos sin distorsión, procisamos hacerlos tridimensionales. 
# Entonces le agregamos, a cada coordenada, la coordenada Z, y como son homogéneas, su valor es 1. 
# La función cv2.projectPoints toma coordenadas tridimensionales de cualquier sistema y los transforma 
# al sistema de coordenadas de la cámara, y utiliza los parámetros intrinsecos para encontrar las proyecciones 
# de los puntos en la imagen. 
# h_corners = np.c_[h_corners.squeeze(), np.ones(len(h_corners))]
# img_pts, _ = cv2.projectPoints(h_corners, (0, 0, 0), (0, 0, 0), camera_matrix, None)

# Como argumento recibe las coordenadas a transformar, dos vectores de rotación y traslación de estos puntos, 
# la matriz de la cámara y en el último argumento definimos como queremos proyectar los puntos, 
# sin o con distorsión. Si le pasamos none, los proyecta sin distorsión. Para proyectarlos con distorsión, 
# debemos pasarle como argumento los coeficientes de distorsión de la cámara.
# La función cv2.undistort elimina la distorsión de la imagen. Recibe como argumentos la imagen a corregir y 
# los parámetros intrínsecos de la cámara.  Devuelve la imagen sin distorsión.

# ud_img = cv2.undistort(img, camera_matrix, dist_coefs)

# A continuación se muestra un ejemplo aplicando todo lo mencionado anteriormente.

import cv2
import numpy as np

camera_matrix = np.load('camera_mat.npy')
dist_coefs = np.load('dist_coefs.npy')
pattern_size = (11, 8)

img = cv2.imread('distortioned.JPG')
img = cv2.resize(img, (800, 600))
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

res, corners = cv2.findChessboardCorners(img_show, pattern_size)
criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 30, 1e-3)
corners = cv2.cornerSubPix(gray, corners, (10, 10), (-1, -1), criteria)

h_corners = cv2.undistortPoints(corners, camera_matrix, dist_coefs)
h_corners = np.c_[h_corners.squeeze(), np.ones(len(h_corners))]
img_pts, _ = cv2.projectPoints(h_corners, (0, 0, 0), (0, 0, 0), camera_matrix, None)

for c in corners:
    cv2.circle(img_show, tuple(c[0]), 10, (0, 255, 0), 2)
for c in img_pts.squeeze().astype(np.float32):
    cv2.circle(img_show, tuple(c), 5, (0, 0, 255), 2)

cv2.imshow('undistorted corners', img_show)
cv2.waitKey()
cv2.destroyAllWindows()

img_pts, _ = cv2.projectPoints(h_corners, (0, 0, 0), (0, 0, 0), camera_matrix, dist_coefs)

for c in img_pts.squeeze().astype(np.float32):
    cv2.circle(img_show, tuple(c), 2, (255, 255, 0), 2)

cv2.imshow('reprojected corners', img_show)
cv2.waitKey()
cv2.destroyAllWindows()

ud_img = cv2.undistort(img, camera_matrix, dist_coefs)
horizontal_concat = np.concatenate((img, ud_img), axis=1)
cv2.imshow('result', horizontal_concat)
cv2.waitKey()
cv2.destroyAllWindows()

